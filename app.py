from __future__ import annotations

import os
from typing import Dict, List, Optional

import streamlit as st

from multiagent_demo import DatabaseConfig, ModelConfig, MultiAgentOrchestrator, WeaviateConfig
from multiagent_demo.chunking import build_chunk_payloads, chunk_text
from multiagent_demo.database import DatabaseManager
from multiagent_demo.weaviate_client import WeaviateManager

st.set_page_config(page_title="å¤š Agent ç¼–æ’ Demo", layout="wide")


# -----------------------------------------------------------------------------
# Session helpers
# -----------------------------------------------------------------------------

def _get_database_manager(config: DatabaseConfig) -> DatabaseManager:
    session_key = "db_manager"
    cfg_key = "db_config"

    stored_config: Optional[DatabaseConfig] = st.session_state.get(cfg_key)
    manager: Optional[DatabaseManager] = st.session_state.get(session_key)

    if manager is not None and stored_config == config:
        return manager

    warning_key = "db_warning"
    try:
        manager = DatabaseManager(config)
        st.session_state[session_key] = manager
        st.session_state[cfg_key] = config
        st.session_state.pop(warning_key, None)
        return manager
    except Exception as exc:  # pragma: no cover - depends on external DB
        fallback = DatabaseConfig()
        manager = DatabaseManager(fallback)
        st.session_state[session_key] = manager
        st.session_state[cfg_key] = fallback
        warning = f"æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œå·²å›é€€åˆ° {fallback.url}: {exc}"
        st.session_state[warning_key] = warning
        return manager


def _get_weaviate_manager(config: WeaviateConfig) -> WeaviateManager:
    session_key = "weaviate_manager"
    cfg_key = "weaviate_config"

    stored_config: Optional[WeaviateConfig] = st.session_state.get(cfg_key)
    manager: Optional[WeaviateManager] = st.session_state.get(session_key)

    if manager is not None and stored_config == config:
        return manager

    manager = WeaviateManager(config)
    # Best-effort schema creation.
    manager.ensure_schema()

    st.session_state[session_key] = manager
    st.session_state[cfg_key] = config
    return manager


def _read_uploaded_file(uploaded_file) -> str:
    data = uploaded_file.read()
    if not data:
        return ""
    for encoding in ("utf-8", "utf-16", "gbk", "latin-1"):
        try:
            return data.decode(encoding)
        except UnicodeDecodeError:
            continue
    return data.decode("utf-8", errors="ignore")


def _model_config_from_inputs() -> ModelConfig:
    return ModelConfig(
        api_key=st.sidebar.text_input(
            "OpenAI API Key",
            value=os.getenv("OPENAI_API_KEY", ""),
            type="password",
            help="æ”¯æŒ OpenAI å…¼å®¹æ¥å£ï¼Œä¾‹å¦‚æœ¬åœ° vLLM / Azure OpenAIã€‚",
        ),
        base_url=st.sidebar.text_input(
            "OpenAI Base URL",
            value=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"),
        ),
        model=st.sidebar.text_input(
            "æ¨¡å‹åç§°",
            value=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
        ),
        temperature=st.sidebar.slider("Temperature", min_value=0.0, max_value=1.5, value=0.2, step=0.05),
        max_tokens=int(
            st.sidebar.number_input("Max Tokens", min_value=64, max_value=4096, value=512, step=32)
        ),
    )


def _weaviate_config_from_inputs() -> WeaviateConfig:
    return WeaviateConfig(
        url=st.sidebar.text_input("Weaviate URL", value=os.getenv("WEAVIATE_URL", "http://localhost:8080")),
        api_key=st.sidebar.text_input("Weaviate API Key", value=os.getenv("WEAVIATE_API_KEY", ""), type="password"),
        class_name=st.sidebar.text_input("Weaviate Class åç§°", value="DocumentChunk"),
    )


def _database_config_from_inputs() -> DatabaseConfig:
    return DatabaseConfig(
        url=st.sidebar.text_input(
            "æ•°æ®åº“è¿æ¥ä¸²",
            value=os.getenv("DATABASE_URL", "sqlite:///demo.db"),
            help="è¾“å…¥ PostgreSQL è¿æ¥ä¸²ï¼Œä¾‹å¦‚ postgresql+psycopg2://user:pass@host:5432/dbnameã€‚",
        ),
        echo=st.sidebar.checkbox("SQL Echo", value=False),
    )


def _show_sidebar_status(weaviate_manager: WeaviateManager) -> None:
    st.sidebar.markdown("---")
    if weaviate_manager.is_connected:
        st.sidebar.success("Weaviate å·²è¿æ¥ï¼Œå‘é‡æ£€ç´¢å¯ç”¨ã€‚")
    else:
        message = weaviate_manager.init_error or "æœªæä¾› Weaviate URLï¼Œå°†ä½¿ç”¨å†…å­˜æ£€ç´¢ã€‚"
        st.sidebar.warning(f"Weaviate æœªè¿æ¥ï¼š{message}")

    db_warning = st.session_state.get("db_warning")
    if db_warning:
        st.sidebar.error(db_warning)

    st.sidebar.markdown("---")
    if "chat_history" in st.session_state:
        st.sidebar.caption(f"å½“å‰ä¼šè¯è½®æ•°ï¼š{len(st.session_state['chat_history']) // 2}")


# -----------------------------------------------------------------------------
# Page layout
# -----------------------------------------------------------------------------

st.title("ğŸ§  å¤š Agent ç¼–æ’ Demo (LangGraph + Weaviate + PG)")
st.caption("ä¸Šä¼ æ–‡æ¡£ â†’ å¤šè·¯æ£€ç´¢ â†’ å·¥å…·/Web æœç´¢ â†’ LLM ç­”å¤")

model_config = _model_config_from_inputs()
weaviate_config = _weaviate_config_from_inputs()
database_config = _database_config_from_inputs()

weaviate_manager = _get_weaviate_manager(weaviate_config)
db_manager = _get_database_manager(database_config)
_show_sidebar_status(weaviate_manager)

st.subheader("æ­¥éª¤ 1ï¼šä¸Šä¼ æ–‡æ¡£å¹¶å†™å…¥çŸ¥è¯†åº“")
uploaded_files = st.file_uploader(
    "ä¸Šä¼ æ–‡æœ¬æ–‡ä»¶ï¼ˆæ”¯æŒ txt / md / csv / jsonï¼‰",
    type=["txt", "md", "csv", "json"],
    accept_multiple_files=True,
    help="æ–‡æ¡£ä¼šè¢«è‡ªåŠ¨åˆ‡åˆ†å¹¶å†™å…¥ Weaviate ä¸ æ•°æ®åº“ã€‚",
)

ingest_col1, ingest_col2 = st.columns(2)
with ingest_col1:
    chunk_size = int(st.number_input("Chunk å¤§å°", min_value=200, max_value=1200, value=500, step=50))
with ingest_col2:
    overlap = int(st.number_input("Chunk é‡å ", min_value=0, max_value=300, value=120, step=10))

if st.button("å†™å…¥çŸ¥è¯†åº“", use_container_width=True):
    if not uploaded_files:
        st.warning("è¯·å…ˆé€‰æ‹©è‡³å°‘ä¸€ä¸ªæ–‡ä»¶ã€‚")
    else:
        ingested: List[Dict[str, int]] = []
        errors: List[str] = []
        for file in uploaded_files:
            text = _read_uploaded_file(file)
            if not text.strip():
                errors.append(f"æ–‡ä»¶ {file.name} å†…å®¹ä¸ºç©ºæˆ–æ— æ³•è¯»å–ã€‚")
                continue

            chunks = chunk_text(text, chunk_size=chunk_size, overlap=overlap)
            payloads = build_chunk_payloads(chunks, source=file.name)

            try:
                document_id = db_manager.ingest_document(file.name, payloads)
            except Exception as exc:  # pragma: no cover - depends on DB
                errors.append(f"å†™å…¥æ•°æ®åº“å¤±è´¥ï¼ˆ{file.name}ï¼‰ï¼š{exc}")
                continue

            for payload in payloads:
                payload["document_id"] = document_id

            weaviate_manager.upsert_texts(payloads)
            ingested.append({"name": file.name, "chunks": len(payloads)})

        if ingested:
            st.success(f"æˆåŠŸå†™å…¥ {len(ingested)} ä¸ªæ–‡ä»¶ã€‚")
            st.json(ingested)
        if errors:
            st.error("\n".join(errors))

st.markdown("---")

st.subheader("æ­¥éª¤ 2ï¼šæé—®å¹¶è§¦å‘å¤š Agent ç¼–æ’")
question = st.text_area("è¯·è¾“å…¥é—®é¢˜", height=120)
run_button = st.button("è¿è¡Œå¤š Agent Workflow", use_container_width=True)

if run_button:
    if not question.strip():
        st.warning("è¯·è¾“å…¥é—®é¢˜åå†è¿è¡Œã€‚")
    else:
        orchestrator = MultiAgentOrchestrator(
            model_config=model_config,
            weaviate_manager=weaviate_manager,
            database_manager=db_manager,
        )
        history = st.session_state.get("chat_history", [])
        result = orchestrator.run(question, chat_history=history)

        st.session_state.setdefault("chat_history", [])
        st.session_state["chat_history"].append({"role": "user", "content": question})
        st.session_state["chat_history"].append({"role": "assistant", "content": result.get("answer", "")})

        st.markdown("### ğŸ¤– æœ€ç»ˆå›ç­”")
        st.write(result.get("answer", "æœªç”Ÿæˆå›ç­”ã€‚"))

        col_vector, col_keyword = st.columns(2)
        with col_vector:
            with st.expander("å‘é‡æ£€ç´¢ç»“æœ", expanded=False):
                for item in result.get("vector_results", []):
                    st.markdown(
                        f"**source:** {item.get('source', 'N/A')} | **chunk:** {item.get('chunk_index')} | "
                        f"**score:** {item.get('score')}\n\n{item.get('text')}"
                    )
                if not result.get("vector_results"):
                    st.info("æ— å‘é‡æ£€ç´¢ç»“æœã€‚")
        with col_keyword:
            with st.expander("å…³é”®è¯æ£€ç´¢ç»“æœ", expanded=False):
                for item in result.get("keyword_results", []):
                    keywords = ", ".join(item.get("keywords", []) or [])
                    st.markdown(
                        f"**æ–‡æ¡£:** {item.get('document')} | **chunk:** {item.get('chunk_index')} | "
                        f"**å…³é”®è¯:** {keywords}\n\n{item.get('text')}"
                    )
                if not result.get("keyword_results"):
                    st.info("æ— å…³é”®è¯æ£€ç´¢ç»“æœã€‚")

        col_knowledge, col_tool = st.columns(2)
        with col_knowledge:
            with st.expander("çŸ¥è¯†å›¾è°±æ£€ç´¢", expanded=False):
                for item in result.get("knowledge_results", []):
                    st.markdown(
                        f"**{item.get('subject')}** -{item.get('predicate')}â†’ **{item.get('object')}**"
                        f" ï¼ˆæ¥æº: {item.get('document')}ï¼‰"
                    )
                if not result.get("knowledge_results"):
                    st.info("æ— çŸ¥è¯†å›¾è°±å‘½ä¸­ã€‚")
        with col_tool:
            with st.expander("å·¥å…·è°ƒç”¨ç»“æœ", expanded=False):
                for item in result.get("tool_outputs", []):
                    st.markdown(f"å·¥å…· {item.get('tool')} è¾“å…¥ `{item.get('input')}` â†’ è¾“å‡º `{item.get('output')}`")
                if not result.get("tool_outputs"):
                    st.info("æœªè§¦å‘å·¥å…·ã€‚")

        with st.expander("Web æœç´¢è¡¥å……", expanded=False):
            for item in result.get("web_results", []):
                st.markdown(
                    f"[{item.get('title') or 'æ— æ ‡é¢˜'}]({item.get('url') or '#'})\n\n"
                    f"{item.get('snippet') or 'æ— æ‘˜è¦'}"
                )
            if not result.get("web_results"):
                st.info("æ—  Web æœç´¢å‘½ä¸­ã€‚")

        if result.get("errors"):
            st.warning("; ".join(result["errors"]))

        st.markdown("---")

st.subheader("æ­¥éª¤ 3ï¼šçŸ¥è¯†åº“æ¦‚è§ˆ")
with st.expander("å·²å†™å…¥æ–‡æ¡£", expanded=False):
    try:
        docs = db_manager.list_documents()
        if docs:
            st.dataframe(docs)
        else:
            st.info("å°šæœªæœ‰æ–‡æ¡£å†™å…¥ã€‚")
    except Exception as exc:  # pragma: no cover - DB dependent
        st.error(f"æ— æ³•è¯»å–æ–‡æ¡£åˆ—è¡¨ï¼š{exc}")

with st.expander("å½“å‰å¯¹è¯å†å²", expanded=False):
    history = st.session_state.get("chat_history", [])
    if not history:
        st.info("æš‚æ— å¯¹è¯è®°å½•ã€‚")
    else:
        for turn in history:
            st.markdown(f"**{turn.get('role')}**: {turn.get('content')}")
